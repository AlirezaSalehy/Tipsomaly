{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working/TipsOmaly/model/demo_sepehr/big_vision\n"
     ]
    }
   ],
   "source": [
    "!pip3 -q install --no-cache-dir -U crcmod # ‼️ NOTE\n",
    "\n",
    "%cd /kaggle/working/TipsOmaly/model/demo_sepehr/big_vision \n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import ml_collections\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working/cpt//siglip2_l16_512.npz  gs://big_vision/siglip2/siglip2_l16_512.npz \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-18 08:36:49.442010: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1760776609.465097   25691 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1760776609.472026   25691 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "# Pick your hero: (WHEN CHANGING THIS, RERUN IMAGE/TEXT EMBEDDING CELLS)\n",
    "# Give this cell 1-3mins.\n",
    "\n",
    "# VARIANT, RES = 'B/32', 256\n",
    "# VARIANT, RES = 'B/16', 224\n",
    "# VARIANT, RES = 'B/16', 256\n",
    "# VARIANT, RES = 'B/16', 384\n",
    "# VARIANT, RES = 'B/16', 512\n",
    "# VARIANT, RES, N_PATCHES = 'B/16', 'naflex', 256\n",
    "# VARIANT, RES = 'L/16', 256\n",
    "# VARIANT, RES = 'L/16', 384\n",
    "VARIANT, RES = 'L/16', 512\n",
    "# VARIANT, RES = 'So400m/16', 256\n",
    "# VARIANT, RES = 'So400m/16', 384\n",
    "# VARIANT, RES = 'So400m/16', 512\n",
    "# VARIANT, RES, N_PATCHES = 'So400m/16', 'naflex', 256\n",
    "# VARIANT, RES = 'So400m/14', 224\n",
    "# VARIANT, RES = 'So400m/14', 384\n",
    "# VARIANT, RES = 'g-opt/16', 256\n",
    "# VARIANT, RES = 'g-opt/16', 384\n",
    "\n",
    "CKPT = f'siglip2_{VARIANT.lower().replace(\"/\", \"\")}_{RES}.npz'\n",
    "TXTVARIANT, PATCH_SIZE = VARIANT.split('/')\n",
    "EMBDIM = {'B': 768, 'L': 1024, 'So400m': 1152, 'g-opt': 1536}[TXTVARIANT]\n",
    "# Note: The g-opt vision encoder is paired with a So400m text encoder\n",
    "TXTVARIANT = 'So400m' if TXTVARIANT == 'g-opt' else TXTVARIANT\n",
    "PATCH_SIZE = int(PATCH_SIZE)\n",
    "VOCAB = 256_000\n",
    "SEQLEN = 64\n",
    "\n",
    "ROOT_PATH='/kaggle/working/cpt/'\n",
    "# It is significantly faster to first copy the checkpoint (30s vs 8m30 for B and 1m vs ??? for L)\n",
    "!test -f {ROOT_PATH}/{CKPT} || gsutil cp gs://big_vision/siglip2/{CKPT} {ROOT_PATH}\n",
    "print(f'{ROOT_PATH}/{CKPT} ', f'gs://big_vision/siglip2/{CKPT} ')\n",
    "\n",
    "\n",
    "import big_vision.models.proj.image_text.two_towers as model_mod\n",
    "\n",
    "model_cfg = ml_collections.ConfigDict(dict(\n",
    "    image_model='vit',\n",
    "    image=dict(\n",
    "        pool_type='map',\n",
    "        scan=True,\n",
    "        variant=VARIANT,\n",
    "    ),\n",
    "    text_model='proj.image_text.text_transformer',\n",
    "    text=dict(\n",
    "        scan=True,\n",
    "        variant=TXTVARIANT,\n",
    "        vocab_size=256_000,\n",
    "    ),\n",
    "    out_dim=[None, EMBDIM],\n",
    "    bias_init=-10,  # without this arg, no \"b\" param is added\n",
    "))\n",
    "model = model_mod.Model(**model_cfg)\n",
    "\n",
    "# Using `init_params` is slower but will lead to `load` below performing sanity-checks.\n",
    "# init_params = jax.jit(model.init, backend=\"cpu\")(jax.random.PRNGKey(42), jnp.zeros([1, RES, RES, 3], jnp.float32), jnp.zeros([1, SEQLEN], jnp.int32))['params']\n",
    "init_params = None  # Faster but bypasses loading sanity-checks.\n",
    "\n",
    "params = model_mod.load(init_params, f'/tmp/{CKPT}', model_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1760776631.924955   25691 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 2941 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n",
      "INFO:2025-10-18 08:37:12,791:jax._src.xla_bridge:924: Unable to initialize backend 'rocm': module 'jaxlib.xla_extension' has no attribute 'GpuAllocatorConfig'\n",
      "INFO:2025-10-18 08:37:12,793:jax._src.xla_bridge:924: Unable to initialize backend 'tpu': INTERNAL: Failed to open libtpu.so: libtpu.so: cannot open shared object file: No such file or directory\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imgs (1, 512, 512, 3)\n",
      "self.pool_type: map\n",
      "zimg (1, 1024)\n"
     ]
    }
   ],
   "source": [
    "import big_vision.pp.builder as pp_builder\n",
    "import big_vision.pp.ops_general\n",
    "import big_vision.pp.ops_image\n",
    "import big_vision.pp.ops_text\n",
    "import big_vision.pp.proj.image_text.ops_naflex\n",
    "import big_vision.pp.proj.paligemma.ops\n",
    "import PIL\n",
    "\n",
    "images = [PIL.Image.open(fname) for fname in [\n",
    "    'apple-ipod.jpg',\n",
    "]]\n",
    "pp_img = pp_builder.get_preprocess_fn(f'resize({RES})|value_range(-1, 1)')\n",
    "imgs = np.array([pp_img({'image': np.array(image)})['image'] for image in images])\n",
    "print('imgs', imgs.shape)\n",
    "zimg, _, out = model.apply({'params': params}, imgs, None)\n",
    "\n",
    "print('zimg', zimg.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img/stem: <class 'jaxlib.xla_extension.ArrayImpl'>, (1, 32, 32, 1024)\n",
      "img/with_posemb: <class 'jaxlib.xla_extension.ArrayImpl'>, (1, 1024, 1024)\n",
      "img/encoder: <class 'dict'>, --\n",
      "img/encoded: <class 'jaxlib.xla_extension.ArrayImpl'>, (1, 1024, 1024)\n",
      "img/head_input: <class 'jaxlib.xla_extension.ArrayImpl'>, (1, 1024)\n",
      "img/pre_logits_2d: <class 'jaxlib.xla_extension.ArrayImpl'>, (1, 32, 32, 1024)\n",
      "img/pre_logits: <class 'jaxlib.xla_extension.ArrayImpl'>, (1, 1024)\n",
      "img/norm: <class 'jaxlib.xla_extension.ArrayImpl'>, (1, 1)\n",
      "img/normalized: <class 'jaxlib.xla_extension.ArrayImpl'>, (1, 1024)\n",
      "img/2d_norm: <class 'jaxlib.xla_extension.ArrayImpl'>, (1, 1024, 1)\n",
      "img/2d_normalized: <class 'jaxlib.xla_extension.ArrayImpl'>, (1, 1024, 1024)\n",
      "t: <class 'jaxlib.xla_extension.ArrayImpl'>, (1,)\n",
      "t/parameter: <class 'numpy.ndarray'>, --\n",
      "b: <class 'numpy.ndarray'>, --\n"
     ]
    }
   ],
   "source": [
    "for k,v in out.items():\n",
    "    if type(v) == type(out['img/stem']):\n",
    "        print(f'{k}: {type(v)}, {v.shape}')\n",
    "    else:\n",
    "        print(f'{k}: {type(v)}, --')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Tokenize and embed texts\n",
    "\n",
    "# texts with translations into random languages\n",
    "texts_dict = {\n",
    "    'an apple': 'tufaha',  # Swahili\n",
    "    'a picture of an apple': 'ένα μήλο',  # Greek (Modern)\n",
    "    'an ipod': 'айпод',  # Russian\n",
    "    'an apple with a note saying \"ipod\"': 'apple na nóta ag rá \"ipod\"',  # Irish\n",
    "    'a cold drink on a hot day': 'en kold drink på en varm dag', # Danish\n",
    "    'a hot drink on a cold day': 'een hete drank op een koude dag', # Dutch\n",
    "    'a photo of a cold drink on a hot day': '炎热天气里一杯冷饮的照片', # Chinese\n",
    "    'a photo of a hot drink on a cold day': 'foto cangkir panas dina dinten tiis',  # Sundanese\n",
    "    #\n",
    "    'a photo of two guys in need of caffeine': 'एक तस्वीर जिसमें दो लोगों को कैफीन की ज़रूरत है',  # Hindi\n",
    "    'a photo of two guys in need of water': 'o imagine a doi tipi care au nevoie de apă',  # Romanian\n",
    "    'a photo of the SigLIP authors': 'foto para penulis SigLIP',  # Indonesian\n",
    "    'a photo of a rock band': 'ロックバンドの写真', # Japanese\n",
    "    'a photo of researchers at Google Brain': 'foto av forskare på Google Brain', # Swedish\n",
    "    'a photo of researchers at OpenAI': 'OpenAI:n tutkijoiden kuva',  # Finnish\n",
    "    #\n",
    "    'cow': 'sapi',  # Indonesian\n",
    "    'a cow in a tuxedo': 'une vache en smoking',  # French\n",
    "    'a cow on the beach': 'פרה על החוף', # Hebrew\n",
    "    #\n",
    "    # Croatian:\n",
    "    'a picture of a laptop with the lockscreen on, a cup of cappucino, salt and pepper grinders. The view through the window reveals lake Zürich and the Alps in the background of the city.': \"slika prijenosnog računala sa zaključanim zaslonom, šalica cappuccina, mlinci za sol i papar. Pogled kroz prozor otkriva jezero Zürich i Alpe u pozadini grada.\",\n",
    "}\n",
    "\n",
    "# ‼️ NOTE: SigLIP 2 models work best with lowercase texts\n",
    "pp_txt = pp_builder.get_preprocess_fn(f'lower(key=\"text\")|tok(length={SEQLEN}, model=\"gemma\", bos=\"no\", eos=\"sticky\", key=\"text\")')\n",
    "\n",
    "\n",
    "def embed_texts(texts):\n",
    "  txts = np.array([pp_txt({'text': text})['text'] for text in texts])\n",
    "  _, ztxt, out = model.apply({'params': params}, None, txts)\n",
    "  return txts, ztxt, dict(t=out['t'], b=out['b'])\n",
    "\n",
    "\n",
    "txts, ztxt, out = embed_texts(texts_dict)\n",
    "print(txts.shape, ztxt.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
